{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EPAI_session 16.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOpNMw4CGf5780kpXKXcbIk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagar9926/EPAI_session16/blob/main/EPAI_session_16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzezb8d1VFrm"
      },
      "source": [
        "## Assignment 1 :\n",
        "\n",
        "The files are:\n",
        "\n",
        "- personal_info.csv - personal information such as name, gender, etc. (one row per person)\n",
        "\n",
        "- vehicles.csv - what vehicle people own (one row per person)\n",
        "\n",
        "- employment.csv - where a person is employed (one row per person)\n",
        "\n",
        "- update_status.csv - when the person's data was created and last updated\n",
        "\n",
        "Each file contains a key, SSN, which uniquely identifies a person.\n",
        "\n",
        "This key is present in all four files.\n",
        "\n",
        "You are guaranteed that the same SSN value is present in every file, and that it only appears once per file.\n",
        "\n",
        "In addition, the files are all sorted by SSN, i.e. the SSN values appear in the same order in each file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9rZleNlTQ9r",
        "outputId": "6ae0b390-1171-476e-dc19-b1fc76466767"
      },
      "source": [
        "!git clone https://github.com/sagar9926/EPAI_session16.git"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'EPAI_session16' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NglzoKIpTYB4",
        "outputId": "35e30ec2-8f98-419f-e106-21eef114c982"
      },
      "source": [
        "cd EPAI_session16"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/EPAI_session16/EPAI_session16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk-oqb8GXDbn",
        "outputId": "b5dc824e-23e2-4465-8231-6389965588dc"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "employment.csv\t       personal_info.csv  update_status.csv\n",
            "EPAI_session_16.ipynb  README.md\t  vehicles.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxnTtvn3ThZV"
      },
      "source": [
        "from collections import namedtuple\n",
        "import datetime\n",
        "import csv"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1oMucRxW4OO"
      },
      "source": [
        "def read_file(file_name):\n",
        "  with open(file_name) as f:\n",
        "    rows = csv.reader(f,delimiter = ',',quotechar = '\"')\n",
        "    yield from rows\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Xi4XiP9xANe"
      },
      "source": [
        "data_type_dict = {\n",
        "    \"employment.csv\" : [str,str,str,str],\n",
        "    'personal_info.csv' : [str,str,str,str,str],\n",
        "    'update_status.csv' : [str,datetime.datetime.strptime,datetime.datetime.strptime],\n",
        "    'vehicles.csv' : [str,\tstr,\tstr,\tint]\n",
        "\n",
        "}\n",
        "date_format = '%Y-%m-%dT%H:%M:%SZ'"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H4Jeo8LT0o6"
      },
      "source": [
        "class file_iter:\n",
        "  def __init__(self,file_name):\n",
        "    self.file_name = file_name\n",
        "    self.data_type = data_type_dict[self.file_name]\n",
        "    self.file = read_file(self.file_name)\n",
        "    self.columns = \" \".join(next(self.file))\n",
        "    self.row_name_tuple = namedtuple((self.file_name[0].upper() + self.file_name[1:-4]),self.columns)\n",
        "    self.row_index = 0\n",
        "  \n",
        "  def __iter__(self):\n",
        "    for row in self.file:\n",
        "      if self.file_name != 'update_status.csv':\n",
        "        row = [type_(data) for type_ , data in zip(self.data_type,row)]\n",
        "      else :\n",
        "        row = [type_(data) if type_ == str else type_(data,date_format) for type_ , data in zip(self.data_type,row)]\n",
        "      yield self.row_name_tuple(*row)\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHzHzLC7sRVn"
      },
      "source": [
        "### Goal 1\n",
        "\n",
        "Your first task is to create iterators for each of the four files that contained cleaned up data, of the correct type (e.g. string, int, date, etc), and represented by a named tuple.\n",
        "\n",
        "For now these four iterators are just separate, independent iterators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg3e5KcMrxou"
      },
      "source": [
        "employment_iter = file_iter('employment.csv')\n",
        "personal_info_iter = file_iter('personal_info.csv')\n",
        "update_status_iter = file_iter('update_status.csv')\n",
        "vehicles_iter = file_iter('vehicles.csv')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DpCJwJ-CjPo",
        "outputId": "7bee0ab7-b34d-4109-efef-4bfdef222cea"
      },
      "source": [
        "count = 0\n",
        "for x in personal_info_iter: \n",
        "  print(x)\n",
        "  count += 1\n",
        "  if count == 3:\n",
        "    break"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Personal_info(ssn='100-53-9824', first_name='Sebastiano', last_name='Tester', gender='Male', language='Icelandic')\n",
            "Personal_info(ssn='101-71-4702', first_name='Cayla', last_name='MacDonagh', gender='Female', language='Lao')\n",
            "Personal_info(ssn='101-84-0356', first_name='Nomi', last_name='Lipprose', gender='Female', language='Yiddish')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq7MR9OTCaLU",
        "outputId": "c0eaf127-6ce1-4a8d-a4a9-0ee6b0f4dd35"
      },
      "source": [
        "count = 0\n",
        "for x in update_status_iter: \n",
        "  print(x)\n",
        "  count += 1\n",
        "  if count == 3:\n",
        "    break"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Update_status(ssn='100-53-9824', last_updated=datetime.datetime(2017, 10, 7, 0, 14, 42), created=datetime.datetime(2016, 1, 24, 21, 19, 30))\n",
            "Update_status(ssn='101-71-4702', last_updated=datetime.datetime(2017, 1, 23, 11, 23, 17), created=datetime.datetime(2016, 1, 27, 4, 32, 57))\n",
            "Update_status(ssn='101-84-0356', last_updated=datetime.datetime(2017, 10, 4, 11, 21, 30), created=datetime.datetime(2016, 9, 21, 23, 4, 7))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up6MrbKACKrs",
        "outputId": "02c65812-e200-4e1a-a94f-c6b4cc7550db"
      },
      "source": [
        "count = 0\n",
        "for x in vehicles_iter: \n",
        "  print(x)\n",
        "  count += 1\n",
        "  if count == 3:\n",
        "    break"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vehicles(ssn='100-53-9824', vehicle_make='Oldsmobile', vehicle_model='Bravada', model_year=1993)\n",
            "Vehicles(ssn='101-71-4702', vehicle_make='Ford', vehicle_model='Mustang', model_year=1997)\n",
            "Vehicles(ssn='101-84-0356', vehicle_make='GMC', vehicle_model='Yukon', model_year=2005)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35338hHcoX8D"
      },
      "source": [
        "qc = file_iter('employment.csv')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Xy7acw9oe3N",
        "outputId": "966b9b51-b108-4018-bce2-466f55b6296b"
      },
      "source": [
        "qc"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.file_iter at 0x7fddc4b5ed30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK07bbC3ohK7",
        "outputId": "1cd072d9-8d66-4302-dd90-87e902a941a3"
      },
      "source": [
        "next(iter(qc))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Employment(employer='Stiedemann-Bailey', department='Research and Development', employee_id='29-0890771', ssn='100-53-9824')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivaeVcou8nBs"
      },
      "source": [
        "### Goal 2\n",
        "\n",
        "Create a single iterable that combines all the columns from all the iterators.\n",
        "\n",
        "The iterable should yield named tuples containing all the columns. Make sure that the SSN's across the files match!\n",
        "\n",
        "All the files are guaranteed to be in SSN sort order, and every SSN is unique, and every SSN appears in every file.\n",
        "\n",
        "Make sure the SSN is not repeated 4 times - one time per row is enough!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5CuKi0rhSeR"
      },
      "source": [
        "employment_iter = file_iter('employment.csv')\n",
        "personal_info_iter = file_iter('personal_info.csv')\n",
        "update_status_iter = file_iter('update_status.csv')\n",
        "vehicles_iter = file_iter('vehicles.csv')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQiG-Tv9AzCK"
      },
      "source": [
        "class AllData :\n",
        "  def __init__(self,employment,personal_info,update_status,vehicles):\n",
        "    self.employment_fname = employment\n",
        "    self.personal_info_fname = personal_info\n",
        "    self.update_status_fname = update_status\n",
        "    self.vehicles_fname = vehicles\n",
        "\n",
        "  def __iter__(self):\n",
        "    return self.AllDataIterator(self.employment_fname,self.personal_info_fname,self.update_status_fname,self.vehicles_fname)\n",
        "\n",
        "  class AllDataIterator:\n",
        "    def __init__(self,employment,personal_info,update_status,vehicles):\n",
        "      self.employment_iter = file_iter(employment)\n",
        "      self.personal_info_iter = file_iter(personal_info)\n",
        "      self.update_status_iter = file_iter(update_status)\n",
        "      self.vehicles_iter = file_iter(vehicles)\n",
        "      self.row_index = 0\n",
        "\n",
        "    def __iter__(self):\n",
        "      return self\n",
        "\n",
        "    def __next__(self):\n",
        "      if self.row_index >= 1000:\n",
        "        raise StopIteration\n",
        "      else:\n",
        "        self.row_index += 1\n",
        "        for employment , personal_info , update_status , vehicles in zip(self.employment_iter,self.personal_info_iter,self.update_status_iter,self.vehicles_iter):\n",
        "          employment_dict = dict(employment._asdict()) \n",
        "          personal_info_dict = dict(personal_info._asdict())\n",
        "          update_status_dict = dict(update_status._asdict())\n",
        "          vehicles_dict = dict(vehicles._asdict())\n",
        "\n",
        "          combined_dict = {**employment_dict , **personal_info_dict , **update_status_dict , **vehicles_dict }\n",
        "          ALL_Data = namedtuple('ALL_Data',combined_dict)\n",
        "\n",
        "          return ALL_Data(**combined_dict)\n",
        "          \n",
        "      "
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skAEe-7QDvSM"
      },
      "source": [
        "qc = AllData('employment.csv','personal_info.csv','update_status.csv','vehicles.csv')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIgefDKEqL_S",
        "outputId": "a4715020-aa44-4614-d0b3-e616cfc660c0"
      },
      "source": [
        "next(iter(qc))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ALL_Data(employer='Stiedemann-Bailey', department='Research and Development', employee_id='29-0890771', ssn='100-53-9824', first_name='Sebastiano', last_name='Tester', gender='Male', language='Icelandic', last_updated=datetime.datetime(2017, 10, 7, 0, 14, 42), created=datetime.datetime(2016, 1, 24, 21, 19, 30), vehicle_make='Oldsmobile', vehicle_model='Bravada', model_year=1993)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpK7fhKapy_C"
      },
      "source": [
        "### Goal 3\n",
        "Next, you want to identify any stale records, where stale simply means the record has not been updated since 3/1/2017 (e.g. last update date < 3/1/2017). Create an iterator that only contains current records (i.e. not stale) based on the last_updated field from the status_update file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBb7IdztpUOm"
      },
      "source": [
        "def Stale_records():\n",
        "  data = AllData('employment.csv','personal_info.csv','update_status.csv','vehicles.csv')\n",
        "  for NT in data:\n",
        "    if NT.last_updated < datetime.datetime.strptime(\"2017/03/01\",\"%Y/%m/%d\"):\n",
        "      yield NT\n",
        "    else :\n",
        "      continue"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbXUOLTWrN0O"
      },
      "source": [
        "### Goal 4\n",
        "Find the largest group of car makes for each gender.\n",
        "\n",
        "Possibly more than one such group per gender exists (equal sizes)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d-kZvEksW1g"
      },
      "source": [
        "data = AllData('employment.csv','personal_info.csv','update_status.csv','vehicles.csv')\n",
        "car_make = {k.vehicle_make : 0 for k in data}\n",
        "\n",
        "gender_car_make = {\"Male\" : car_make.copy(), \"Female\" : car_make.copy()}\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCNkxwETs9YH"
      },
      "source": [
        "for row in data:\n",
        "  gender_car_make[row.gender][row.vehicle_make] += 1"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUGal8UBs_Rq",
        "outputId": "1165a3de-7b41-4dbf-d4d3-6b97aeb662b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sorted(gender_car_make['Female'].items(), key = lambda x : x[1],reverse = True)[:3]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Ford', 48), ('Chevrolet', 48), ('Mitsubishi', 25)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3Ye7mFlq95q",
        "outputId": "c4335ba8-7ece-44ba-9f56-09b231f0de19"
      },
      "source": [
        "sorted(gender_car_make['Male'].items(), key = lambda x : x[1],reverse = True)[:3]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Ford', 44), ('Chevrolet', 38), ('GMC', 31)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nryl9PPbxGXA",
        "outputId": "6950608d-07a3-4ddb-afab-02935a3ef308",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Largest number of car makes for Males : \", sorted(gender_car_make['Male'].items(), key = lambda x : x[1],reverse = True)[:1])\n",
        "print(\"Largest number of car makes for Females : \", sorted(gender_car_make['Female'].items(), key = lambda x : x[1],reverse = True)[:2])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Largest number of car makes for Males :  [('Ford', 44)]\n",
            "Largest number of car makes for Females :  [('Ford', 48), ('Chevrolet', 48)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0T8weyKxoWv"
      },
      "source": [
        "## Assignment 2 :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tuEkqJgxugw"
      },
      "source": [
        "### Goal 1\n",
        "For this goal, you are given a number of CSV files, each of which have their first row with the field name.\n",
        "\n",
        "You goal is to create a context manager that you can use to produce the data from each file in a named tuple with field names corresponding to the header row field names.\n",
        "\n",
        "You should use the csv module's reader function to help with parsing the data.\n",
        "\n",
        "Your context manager should be generic in the sense that it should just need the file name, no other configuration or hardcoded functionality is required. You do not need to worry about data types for this goal - just return every field as a string.\n",
        "\n",
        "In addition, your context manager should produce lazy iterators.\n",
        "\n",
        "Implement this using a class that implements the context manager protocol"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMfOf0JIxqg6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
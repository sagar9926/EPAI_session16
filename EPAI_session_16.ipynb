{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EPAI_session 16.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOlhIA0R1yQXPb2kyfgDxPa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagar9926/EPAI_session16/blob/main/EPAI_session_16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzezb8d1VFrm"
      },
      "source": [
        "## Assignment 1 :\n",
        "\n",
        "The files are:\n",
        "\n",
        "- personal_info.csv - personal information such as name, gender, etc. (one row per person)\n",
        "\n",
        "- vehicles.csv - what vehicle people own (one row per person)\n",
        "\n",
        "- employment.csv - where a person is employed (one row per person)\n",
        "\n",
        "- update_status.csv - when the person's data was created and last updated\n",
        "\n",
        "Each file contains a key, SSN, which uniquely identifies a person.\n",
        "\n",
        "This key is present in all four files.\n",
        "\n",
        "You are guaranteed that the same SSN value is present in every file, and that it only appears once per file.\n",
        "\n",
        "In addition, the files are all sorted by SSN, i.e. the SSN values appear in the same order in each file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9rZleNlTQ9r",
        "outputId": "f963cd1c-08f3-425c-e15d-ce9c050cabed"
      },
      "source": [
        "!git clone https://github.com/sagar9926/EPAI_session16.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'EPAI_session16' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NglzoKIpTYB4",
        "outputId": "e8b8e39b-b45b-4f32-da82-3143c05aae6d"
      },
      "source": [
        "cd EPAI_session16"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/EPAI_session16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk-oqb8GXDbn",
        "outputId": "7012ec87-8500-4418-a503-5dabe2817313"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "employment.csv\tEPAI_session_16.ipynb  README.md\t  vehicles.csv\n",
            "EPAI_session16\tpersonal_info.csv      update_status.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxnTtvn3ThZV"
      },
      "source": [
        "from collections import namedtuple\n",
        "import datetime\n",
        "import csv"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1oMucRxW4OO"
      },
      "source": [
        "def read_file(file_name):\n",
        "  with open(file_name) as f:\n",
        "    rows = csv.reader(f,delimiter = ',',quotechar = '\"')\n",
        "    yield from rows\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Xi4XiP9xANe"
      },
      "source": [
        "data_type_dict = {\n",
        "    \"employment.csv\" : [str,str,str,str],\n",
        "    'personal_info.csv' : [str,str,str,str,str],\n",
        "    'update_status.csv' : [str,datetime.datetime.strptime,datetime.datetime.strptime],\n",
        "    'vehicles.csv' : [str,\tstr,\tstr,\tint]\n",
        "\n",
        "}\n",
        "date_format = '%Y-%m-%dT%H:%M:%SZ'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H4Jeo8LT0o6"
      },
      "source": [
        "class file_iter:\n",
        "  def __init__(self,file_name):\n",
        "    self.file_name = file_name\n",
        "    self.data_type = data_type_dict[self.file_name]\n",
        "    self.file = read_file(self.file_name)\n",
        "    self.columns = \" \".join(next(self.file))\n",
        "    self.row_name_tuple = namedtuple((self.file_name[0].upper() + self.file_name[1:-4]),self.columns)\n",
        "    self.row_index = 0\n",
        "  \n",
        "  def __iter__(self):\n",
        "    for row in self.file:\n",
        "      if self.file_name != 'update_status.csv':\n",
        "        row = [type_(data) for type_ , data in zip(self.data_type,row)]\n",
        "      else :\n",
        "        row = [type_(data) if type_ == str else type_(data,date_format) for type_ , data in zip(self.data_type,row)]\n",
        "      yield self.row_name_tuple(*row)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHzHzLC7sRVn"
      },
      "source": [
        "### Goal 1\n",
        "\n",
        "Your first task is to create iterators for each of the four files that contained cleaned up data, of the correct type (e.g. string, int, date, etc), and represented by a named tuple.\n",
        "\n",
        "For now these four iterators are just separate, independent iterators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg3e5KcMrxou"
      },
      "source": [
        "employment_iter = file_iter('employment.csv')\n",
        "personal_info_iter = file_iter('personal_info.csv')\n",
        "update_status_iter = file_iter('update_status.csv')\n",
        "vehicles_iter = file_iter('vehicles.csv')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DpCJwJ-CjPo",
        "outputId": "c0703508-0de9-4ede-878d-c6bff68e254a"
      },
      "source": [
        "count = 0\n",
        "for x in personal_info_iter: \n",
        "  print(x)\n",
        "  count += 1\n",
        "  if count == 3:\n",
        "    break"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Personal_info(ssn='100-53-9824', first_name='Sebastiano', last_name='Tester', gender='Male', language='Icelandic')\n",
            "Personal_info(ssn='101-71-4702', first_name='Cayla', last_name='MacDonagh', gender='Female', language='Lao')\n",
            "Personal_info(ssn='101-84-0356', first_name='Nomi', last_name='Lipprose', gender='Female', language='Yiddish')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq7MR9OTCaLU",
        "outputId": "893c5a12-7736-4e7f-f58d-627b03a32d7b"
      },
      "source": [
        "count = 0\n",
        "for x in update_status_iter: \n",
        "  print(x)\n",
        "  count += 1\n",
        "  if count == 3:\n",
        "    break"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Update_status(ssn='100-53-9824', last_updated=datetime.datetime(2017, 10, 7, 0, 14, 42), created=datetime.datetime(2016, 1, 24, 21, 19, 30))\n",
            "Update_status(ssn='101-71-4702', last_updated=datetime.datetime(2017, 1, 23, 11, 23, 17), created=datetime.datetime(2016, 1, 27, 4, 32, 57))\n",
            "Update_status(ssn='101-84-0356', last_updated=datetime.datetime(2017, 10, 4, 11, 21, 30), created=datetime.datetime(2016, 9, 21, 23, 4, 7))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up6MrbKACKrs",
        "outputId": "fbfea050-8e21-42aa-9f83-71855af68328"
      },
      "source": [
        "count = 0\n",
        "for x in vehicles_iter: \n",
        "  print(x)\n",
        "  count += 1\n",
        "  if count == 3:\n",
        "    break"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vehicles(ssn='100-53-9824', vehicle_make='Oldsmobile', vehicle_model='Bravada', model_year=1993)\n",
            "Vehicles(ssn='101-71-4702', vehicle_make='Ford', vehicle_model='Mustang', model_year=1997)\n",
            "Vehicles(ssn='101-84-0356', vehicle_make='GMC', vehicle_model='Yukon', model_year=2005)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35338hHcoX8D"
      },
      "source": [
        "qc = file_iter('employment.csv')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Xy7acw9oe3N",
        "outputId": "49c339ba-0b88-4fb8-e20c-f10451a98341"
      },
      "source": [
        "qc"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.file_iter at 0x7fd39d0721d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK07bbC3ohK7",
        "outputId": "38eb4f97-e28b-498d-d182-00e72ca78144"
      },
      "source": [
        "next(iter(qc))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Employment(employer='Stiedemann-Bailey', department='Research and Development', employee_id='29-0890771', ssn='100-53-9824')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivaeVcou8nBs"
      },
      "source": [
        "## Goal 2\n",
        "\n",
        "Create a single iterable that combines all the columns from all the iterators.\n",
        "\n",
        "The iterable should yield named tuples containing all the columns. Make sure that the SSN's across the files match!\n",
        "\n",
        "All the files are guaranteed to be in SSN sort order, and every SSN is unique, and every SSN appears in every file.\n",
        "\n",
        "Make sure the SSN is not repeated 4 times - one time per row is enough!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5CuKi0rhSeR"
      },
      "source": [
        "employment_iter = file_iter('employment.csv')\n",
        "personal_info_iter = file_iter('personal_info.csv')\n",
        "update_status_iter = file_iter('update_status.csv')\n",
        "vehicles_iter = file_iter('vehicles.csv')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQiG-Tv9AzCK"
      },
      "source": [
        "class AllData :\n",
        "  def __init__(self,employment,personal_info,update_status,vehicles):\n",
        "    self.employment_fname = employment\n",
        "    self.personal_info_fname = personal_info\n",
        "    self.update_status_fname = update_status\n",
        "    self.vehicles_fname = vehicles\n",
        "\n",
        "  def __iter__(self):\n",
        "    return self.AllDataIterator(self.employment_fname,self.personal_info_fname,self.update_status_fname,self.vehicles_fname)\n",
        "\n",
        "  class AllDataIterator:\n",
        "    def __init__(self,employment,personal_info,update_status,vehicles):\n",
        "      self.employment_iter = file_iter(employment)\n",
        "      self.personal_info_iter = file_iter(personal_info)\n",
        "      self.update_status_iter = file_iter(update_status)\n",
        "      self.vehicles_iter = file_iter(vehicles)\n",
        "      self.row_index = 0\n",
        "\n",
        "    def __iter__(self):\n",
        "      return self\n",
        "\n",
        "    def __next__(self):\n",
        "      if self.row_index >= 1000:\n",
        "        raise StopIteration\n",
        "      else:\n",
        "        self.row_index += 1\n",
        "        for employment , personal_info , update_status , vehicles in zip(self.employment_iter,self.personal_info_iter,self.update_status_iter,self.vehicles_iter):\n",
        "          employment_dict = dict(employment._asdict()) \n",
        "          personal_info_dict = dict(personal_info._asdict())\n",
        "          update_status_dict = dict(update_status._asdict())\n",
        "          vehicles_dict = dict(vehicles._asdict())\n",
        "\n",
        "          combined_dict = {**employment_dict , **personal_info_dict , **update_status_dict , **vehicles_dict }\n",
        "          ALL_Data = namedtuple('ALL_Data',combined_dict)\n",
        "\n",
        "          return ALL_Data(**combined_dict)\n",
        "          \n",
        "      "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skAEe-7QDvSM"
      },
      "source": [
        "qc = AllData('employment.csv','personal_info.csv','update_status.csv','vehicles.csv')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIgefDKEqL_S",
        "outputId": "485ee63c-7596-42db-9f18-de6456aebfa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "next(iter(qc))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "employment ,  employment.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ALL_Data(employer='Stiedemann-Bailey', department='Research and Development', employee_id='29-0890771', ssn='100-53-9824', first_name='Sebastiano', last_name='Tester', gender='Male', language='Icelandic', last_updated=datetime.datetime(2017, 10, 7, 0, 14, 42), created=datetime.datetime(2016, 1, 24, 21, 19, 30), vehicle_make='Oldsmobile', vehicle_model='Bravada', model_year=1993)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpK7fhKapy_C"
      },
      "source": [
        "### Goal 3\n",
        "Next, you want to identify any stale records, where stale simply means the record has not been updated since 3/1/2017 (e.g. last update date < 3/1/2017). Create an iterator that only contains current records (i.e. not stale) based on the last_updated field from the status_update file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBb7IdztpUOm"
      },
      "source": [
        "def Stale_records():\n",
        "  data = AllData('employment.csv','personal_info.csv','update_status.csv','vehicles.csv')\n",
        "  for NT in data:\n",
        "    if NT.last_updated < datetime.datetime.strptime(\"2017/03/01\",\"%Y/%m/%d\"):\n",
        "      yield NT\n",
        "    else :\n",
        "      continue"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbXUOLTWrN0O"
      },
      "source": [
        "### Goal 4\n",
        "Find the largest group of car makes for each gender.\n",
        "\n",
        "Possibly more than one such group per gender exists (equal sizes)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3Ye7mFlq95q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
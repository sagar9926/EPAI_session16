{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EPAI_session 16.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyObFZXRKisR6YVCxPQNNm9E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagar9926/EPAI_session16/blob/main/EPAI_session_16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzezb8d1VFrm"
      },
      "source": [
        "## Assignment 1 :\n",
        "\n",
        "The files are:\n",
        "\n",
        "- personal_info.csv - personal information such as name, gender, etc. (one row per person)\n",
        "\n",
        "- vehicles.csv - what vehicle people own (one row per person)\n",
        "\n",
        "- employment.csv - where a person is employed (one row per person)\n",
        "\n",
        "- update_status.csv - when the person's data was created and last updated\n",
        "\n",
        "Each file contains a key, SSN, which uniquely identifies a person.\n",
        "\n",
        "This key is present in all four files.\n",
        "\n",
        "You are guaranteed that the same SSN value is present in every file, and that it only appears once per file.\n",
        "\n",
        "In addition, the files are all sorted by SSN, i.e. the SSN values appear in the same order in each file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9rZleNlTQ9r",
        "outputId": "bfdb1441-448f-4ffd-8bec-0aff1a7e2edb"
      },
      "source": [
        "!git clone https://github.com/sagar9926/EPAI_session16.git"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'EPAI_session16'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 21 (delta 5), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (21/21), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NglzoKIpTYB4",
        "outputId": "8b347570-6be7-450e-bce9-d8765606f58f"
      },
      "source": [
        "cd EPAI_session16"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/EPAI_session16/EPAI_session16/EPAI_session16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk-oqb8GXDbn",
        "outputId": "2758f431-024a-4a47-9b93-b33aff11e0e9"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "employment.csv\t       personal_info.csv  update_status.csv\n",
            "EPAI_session_16.ipynb  README.md\t  vehicles.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxnTtvn3ThZV"
      },
      "source": [
        "from collections import namedtuple\n",
        "import datetime\n",
        "import csv"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1oMucRxW4OO"
      },
      "source": [
        "def read_file(file_name):\n",
        "  with open(file_name) as f:\n",
        "    rows = csv.reader(f,delimiter = ',',quotechar = '\"')\n",
        "    yield from rows\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Xi4XiP9xANe"
      },
      "source": [
        "data_type_dict = {\n",
        "    \"employment.csv\" : [str,str,str,str],\n",
        "    'personal_info.csv' : [str,str,str,str,str],\n",
        "    'update_status.csv' : [str,datetime.datetime.strptime,datetime.datetime.strptime],\n",
        "    'vehicles.csv' : [str,\tstr,\tstr,\tstr]\n",
        "\n",
        "}\n",
        "date_format = '%Y-%m-%dT%H:%M:%SZ'"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H4Jeo8LT0o6"
      },
      "source": [
        "class file_iter:\n",
        "  def __init__(self,file_name):\n",
        "    self.file_name = file_name\n",
        "    self.data_type = data_type_dict[self.file_name]\n",
        "    self.file = read_file(self.file_name)\n",
        "    self.columns = \" \".join(next(self.file))\n",
        "    self.row_name_tuple = namedtuple((self.file_name[0].upper() + self.file_name[1:-4]),self.columns)\n",
        "    self.row_index = 0\n",
        "  \n",
        "  def __iter__(self):\n",
        "    for row in self.file:\n",
        "      if self.file_name != 'update_status.csv':\n",
        "        row = [type_(data) for type_ , data in zip(self.data_type,row)]\n",
        "      else :\n",
        "        row = [type_(data) if type_ == str else type_(data,date_format) for type_ , data in zip(self.data_type,row)]\n",
        "      yield self.row_name_tuple(*row)\n",
        "\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHzHzLC7sRVn"
      },
      "source": [
        "### Goal 1\n",
        "\n",
        "Your first task is to create iterators for each of the four files that contained cleaned up data, of the correct type (e.g. string, int, date, etc), and represented by a named tuple.\n",
        "\n",
        "For now these four iterators are just separate, independent iterators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg3e5KcMrxou"
      },
      "source": [
        "employment_iter = file_iter('employment.csv')\n",
        "personal_info_iter = file_iter('personal_info.csv')\n",
        "update_status_iter = file_iter('update_status.csv')\n",
        "vehicles_iter = file_iter('vehicles.csv')"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivaeVcou8nBs"
      },
      "source": [
        "## Goal 2\n",
        "\n",
        "Create a single iterable that combines all the columns from all the iterators.\n",
        "\n",
        "The iterable should yield named tuples containing all the columns. Make sure that the SSN's across the files match!\n",
        "\n",
        "All the files are guaranteed to be in SSN sort order, and every SSN is unique, and every SSN appears in every file.\n",
        "\n",
        "Make sure the SSN is not repeated 4 times - one time per row is enough!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcpkyR496bbn"
      },
      "source": [
        "class Data_Iterable :\n",
        "  def __init__(self,employment_iter,personal_info_iter,update_status_iter,vehicles_iter):\n",
        "    self.employment_iter = employment_iter\n",
        "    self.personal_info_iter = personal_info_iter\n",
        "    self.update_status_iter = update_status_iter\n",
        "    self.vehicles_iter = vehicles_iter\n",
        "\n",
        "  def __iter__(self):\n",
        "    "
      ],
      "execution_count": 67,
      "outputs": []
    }
  ]
}